# 2024--2025
## Related to LLM/ML (NOT AI4SCI)

### Research Article (100-150 papers per year)
  
    Dimensions underlying the representational alignment of deep neural networks with humans
    
    Human-like object concept representations emerge naturally in multimodal large language models
    
    Lossless data compression by large models
    
    Explainable AI reveals Clever Hans effects in unsupervised learning models
    
    Large language models that replace human participants can harmfully misportray and flatten identity groups

    What large language models know and what people think they know

    Visual cognition in multimodal large language models

    Investigating machine moral judgement through the Delphi experiment

    Contextual feature extraction hierarchies converge in large language models and the brain

    Sequential memory improves sample and memory efficiency in episodic control

    Poisoning medical knowledge using large language models

    Efficient and scalable reinforcement learning for large-scale network control

    A large-scale audit of dataset licensing and attribution in AI 

    On responsible machine learning datasets emphasizing fairness, privacy and regulatory norms with examples in biometrics and healthcare

    Automated construction of cognitive maps with visual predictive coding

    Systematic analysis of 32,111 AI model cards characterizes documentation practice in AI [Meta-analysis]

    Reconciling privacy and accuracy in AI for medical imaging

### Analysis (very few papers, benchmark and meta-analysis, usually less than 5 per year)

    A taxonomy and review of generalization research in NLP [Meta-analysis]
    
    Forecasting the future of artificial intelligence with machine learning-based link prediction in an exponentially growing knowledge network [Meta-analysis]

### Review Article (very few papers, survey and meta-analysis, usually less than 5 per year)

    Rethinking machine unlearning for large language models
    
    AI safety for everyone [Meta-analysis]
    
    Learning from models beyond fine-tuning
